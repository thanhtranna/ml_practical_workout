{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170822bc",
   "metadata": {},
   "source": [
    "# TRAFFIC SIGNS CLASSIFICATION USING LE-NET ARCHITECTURE IN KERAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b15323",
   "metadata": {},
   "source": [
    "- In this case study, you have been provided with images of traffic signs and the goal is to train a Deep Network to classify them\n",
    "- The dataset contains 43 different classes of images.\n",
    "- Classes are as listed below:\n",
    "\n",
    "  - ( 0, b'Speed limit (20km/h)') ( 1, b'Speed limit (30km/h)')\n",
    "  - ( 2, b'Speed limit (50km/h)') ( 3, b'Speed limit (60km/h)')\n",
    "  - ( 4, b'Speed limit (70km/h)') ( 5, b'Speed limit (80km/h)')\n",
    "  - ( 6, b'End of speed limit (80km/h)') ( 7, b'Speed limit (100km/h)')\n",
    "  - ( 8, b'Speed limit (120km/h)') ( 9, b'No passing')\n",
    "  - (10, b'No passing for vehicles over 3.5 metric tons')\n",
    "  - (11, b'Right-of-way at the next intersection') (12, b'Priority road')\n",
    "  - (13, b'Yield') (14, b'Stop') (15, b'No vehicles')\n",
    "  - (16, b'Vehicles over 3.5 metric tons prohibited') (17, b'No entry')\n",
    "  - (18, b'General caution') (19, b'Dangerous curve to the left')\n",
    "  - (20, b'Dangerous curve to the right') (21, b'Double curve')\n",
    "  - (22, b'Bumpy road') (23, b'Slippery road')\n",
    "  - (24, b'Road narrows on the right') (25, b'Road work')\n",
    "  - (26, b'Traffic signals') (27, b'Pedestrians') (28, b'Children crossing')\n",
    "  - (29, b'Bicycles crossing') (30, b'Beware of ice/snow')\n",
    "  - (31, b'Wild animals crossing')\n",
    "  - (32, b'End of all speed and passing limits') (33, b'Turn right ahead')\n",
    "  - (34, b'Turn left ahead') (35, b'Ahead only') (36, b'Go straight or right')\n",
    "  - (37, b'Go straight or left') (38, b'Keep right') (39, b'Keep left')\n",
    "  - (40, b'Roundabout mandatory') (41, b'End of no passing')\n",
    "  - (42, b'End of no passing by vehicles over 3.5 metric tons')\n",
    "\n",
    "- The network used is called Le-Net that was presented by Yann LeCun\n",
    "  http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab3eb0",
   "metadata": {},
   "source": [
    "Citation\n",
    "\n",
    "J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453â€“1460. 2011.\n",
    "\n",
    "@inproceedings{Stallkamp-IJCNN-2011,\n",
    "author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel},\n",
    "booktitle = {IEEE International Joint Conference on Neural Networks},\n",
    "title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition},\n",
    "year = {2011},\n",
    "pages = {1453--1460}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc8943",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/ahemateja19bec1025/traffic-sign-dataset-classification/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2e34a",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES AND DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c03f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip setuptools wheel tensorflow==2.13.0 protobuf==3.20.3 numpy seaborn scikit-learn visualkeras scikit-image pydot graphviz pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf989a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable all warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from skimage.io import  imread, imshow\n",
    "from skimage.transform import  resize, rescale\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d208cd8",
   "metadata": {},
   "source": [
    "## LOAD THE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_gen = ImageDataGenerator(zoom_range=0.5, shear_range=0.8, horizontal_flip=True, rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d45339",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./p5_traffic_sign_classification\"\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"traffic_Data\", \"DATA\")\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"traffic_Data\", \"TEST\")\n",
    "data_train_gen =traindata_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(224,224),\n",
    "    batch_size=3,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode='rgb',\n",
    "    seed = 1234,\n",
    "    shuffle = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4367261",
   "metadata": {},
   "source": [
    "## TEST DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6008a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "for img_path in glob.glob(os.path.join(TEST_DIR, \"*\")):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # divide by 255.0 to get float values between 0 and 1 (Rescale)\n",
    "    all_images.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(all_images[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174837f",
   "metadata": {},
   "source": [
    "## IMPORT THE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model = ResNet50(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245efe6e",
   "metadata": {},
   "source": [
    "### MODEL ARCHITECTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "\n",
    "def reset_graph(seed=41):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "\n",
    "visualkeras.layered_view(ResNet50_model, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d019647",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ResNet50_model, to_file= 'ResNet50_model.png', show_shapes = True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Tuning\n",
    "\n",
    "f1=Flatten()(ResNet50_model.output)\n",
    "final_layer=Dense(58,activation='Softmax')(f1)\n",
    "final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=ResNet50_model.input,outputs=final_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc139a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file= 'model.png', show_shapes = True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2893ddd",
   "metadata": {},
   "source": [
    "### MODEL TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde94454",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph(seed=9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c44063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training = model.fit_generator(data_train_gen, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
